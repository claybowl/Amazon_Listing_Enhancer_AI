// Gemini Imagen 3 service for advanced image generation (now using Vertex AI)

export interface ImagenGenerationOptions {
  prompt: string
  numberOfImages?: number
  aspectRatio?: "ASPECT_RATIO_1_1" | "ASPECT_RATIO_9_16" | "ASPECT_RATIO_16_9" | "ASPECT_RATIO_4_3" | "ASPECT_RATIO_3_4"
  style?: "photographic" | "digital_art" | "sketch" | "watercolor" | "oil_painting" | "anime"
  quality?: "standard" | "hd" // This might map to specific Vertex AI params or be part of prompt
  safetyLevel?: "low" | "medium" | "high" // Vertex AI has its own safety filtering
  seed?: number
  guidanceScale?: number // Check Vertex AI documentation for exact parameter name and range
}

export interface ImagenGenerationResult {
  images: string[] // base64 encoded images
  metadata: {
    prompt: string
    aspectRatio: string
    style?: string
    quality?: string
    generationTime: number
    modelVersion: string
  }
}

// Post-processing options remain the same conceptually
export interface ImagenPostProcessingOptions {
  upscale?: boolean
  upscaleLevel?: 2 | 4
  styleTransfer?: {
    enabled: boolean
    targetStyle?: "enhance" | "artistic" | "vintage" | "modern"
  }
  colorAdjustment?: {
    brightness?: number // -100 to 100
    contrast?: number // -100 to 100
    saturation?: number // -100 to 100
  }
}

// Rate limiter remains the same
export class ImagenRateLimiter {
  private requests: number[] = []
  private readonly maxRequests: number = 60 // Adjust as per Vertex AI limits
  private readonly timeWindow: number = 60 * 1000

  canMakeRequest(): boolean {
    const now = Date.now()
    this.requests = this.requests.filter((timestamp) => now - timestamp < this.timeWindow)
    return this.requests.length < this.maxRequests
  }

  recordRequest(): void {
    this.requests.push(Date.now())
  }

  getTimeUntilNextRequest(): number {
    if (this.canMakeRequest()) return 0
    const oldestRequest = Math.min(...this.requests)
    return this.timeWindow - (Date.now() - oldestRequest)
  }

  getRemainingRequests(): number {
    const now = Date.now()
    this.requests = this.requests.filter((timestamp) => now - timestamp < this.timeWindow)
    return Math.max(0, this.maxRequests - this.requests.length)
  }
}

const rateLimiter = new ImagenRateLimiter()

// Client-side generation is generally not recommended for Vertex AI due to auth complexity.
// This function is kept for structural similarity but might be removed or heavily adapted.
// For Vertex AI, server-side calls are strongly preferred.
async function generateImagesClientSide(
  options: ImagenGenerationOptions,
  apiKey: string, // This would need to be an OAuth2 token or a specially configured API key
  projectId: string,
  region: string,
  startTime: number,
): Promise<ImagenGenerationResult> {
  console.warn("Client-side generation with Vertex AI is complex and may not work with simple API keys.")

  const { prompt, numberOfImages = 1, aspectRatio, style, seed, guidanceScale } = options

  const finalPrompt = style ? enhancePromptForStyle(prompt, style) : prompt

  const vertexParameters: Record<string, any> = {
    sampleCount: Math.min(Math.max(numberOfImages, 1), 4),
    aspectRatio: mapAspectRatioClient(aspectRatio),
  }
  if (seed) vertexParameters.seed = seed
  if (guidanceScale) vertexParameters.guidanceScale = guidanceScale

  const requestBody = {
    instances: [{ prompt: finalPrompt }],
    parameters: vertexParameters,
  }

  const MODEL_ID = "imagen-3.0-generate-preview-0619" // Or your chosen model
  const endpoint = `https://${region}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${region}/publishers/google/models/${MODEL_ID}:predict`

  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`, // Requires apiKey to be a valid OAuth2 token
    },
    body: JSON.stringify(requestBody),
  })

  if (!response.ok) {
    const errorText = await response.text()
    console.error("Client-side Vertex AI Imagen API error:", response.status, errorText)
    throw new Error(`Client-side Vertex AI Error: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  rateLimiter.recordRequest() // Record even for client-side if it were to work

  if (!data.predictions || data.predictions.length === 0) {
    throw new Error("No images generated by client-side Vertex AI call")
  }

  const images = data.predictions.map((pred: any) => pred.bytesBase64Encoded).filter(Boolean) as string[]

  return {
    images,
    metadata: {
      prompt: finalPrompt,
      aspectRatio: vertexParameters.aspectRatio,
      style,
      generationTime: Date.now() - startTime,
      modelVersion: MODEL_ID,
    },
  }
}

export async function generateImagesWithImagen(
  options: ImagenGenerationOptions,
  // API key, project ID, region might be passed for client-side, but server-side is preferred
  // For server-side, these are sourced from environment variables in the API route
  _apiKey?: string,
  _projectId?: string,
  _region?: string,
): Promise<ImagenGenerationResult> {
  const startTime = Date.now()

  if (!rateLimiter.canMakeRequest()) {
    const waitTime = rateLimiter.getTimeUntilNextRequest()
    throw new Error(`Rate limit exceeded. Please wait ${Math.ceil(waitTime / 1000)} seconds.`)
  }

  try {
    // Always prefer server-side for Vertex AI
    const serverResponse = await fetch("/api/gemini/generate-images-advanced", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(options),
    })

    if (!serverResponse.ok) {
      const errorData = await serverResponse.json().catch(() => ({ error: "Unknown server error" }))
      console.error("Server error calling /api/gemini/generate-images-advanced:", errorData.error)
      throw new Error(errorData.error || `Server responded with ${serverResponse.status}`)
    }

    rateLimiter.recordRequest()
    const data = await serverResponse.json()

    // Ensure metadata from server is correctly propagated
    return {
      images: data.images,
      metadata: {
        ...data.metadata, // Spread server metadata first
        prompt: data.metadata.prompt || options.prompt, // Ensure prompt is there
        aspectRatio: data.metadata.aspectRatio || mapAspectRatioClient(options.aspectRatio), // Ensure aspect ratio
        style: data.metadata.style || options.style,
        quality: data.metadata.quality || options.quality,
        generationTime: Date.now() - startTime, // Recalculate client-perceived time
        modelVersion: data.metadata.modelVersion, // Use server model version
      },
    }
  } catch (error) {
    console.error("Error generating images with Imagen (Vertex AI via server):", error)
    throw error instanceof Error ? error : new Error("Failed to generate images")
  }
}

// Helper for client-side mapping, similar to server-side
function mapAspectRatioClient(aspectRatio?: string): string {
  switch (aspectRatio) {
    case "ASPECT_RATIO_1_1":
      return "1:1"
    case "ASPECT_RATIO_9_16":
      return "9:16"
    case "ASPECT_RATIO_16_9":
      return "16:9"
    case "ASPECT_RATIO_4_3":
      return "4:3"
    case "ASPECT_RATIO_3_4":
      return "3:4"
    default:
      return "1:1"
  }
}

// Helper for prompt enhancement, similar to server-side
function enhancePromptForStyle(prompt: string, style?: string): string {
  if (!style) return prompt
  const styleEnhancements: Record<string, string> = {
    photographic: "professional photography, high resolution, detailed, realistic lighting",
    digital_art: "digital art, concept art, detailed illustration, vibrant colors",
    sketch: "pencil sketch, hand-drawn, artistic sketch, detailed line art",
    watercolor: "watercolor painting, soft colors, artistic, flowing paint effects",
    oil_painting: "oil painting, classical art style, rich textures, painterly",
    anime: "anime style, manga art, detailed character design, vibrant anime colors",
  }
  const enhancement = styleEnhancements[style]
  return enhancement ? `${prompt}, ${enhancement}` : prompt
}

// Post-processing function remains largely conceptual
export async function postProcessImage(base64Image: string, options: ImagenPostProcessingOptions): Promise<string> {
  console.log("Post-processing options:", options)
  // Placeholder for actual post-processing
  return base64Image
}

export { rateLimiter }
